{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a dataframe from various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe from a dictionary\n",
    "canteens_dict = {\"Name\" : [\"North Spine\", \"Koufu\", \"Canteen 9\", \"North Hill\", \"Canteen 11\"],\n",
    "                 \"Stalls\" : [20, 15, 10, 12, 8],\n",
    "                 \"Rating\" : [4.5, 4.2, 4.0, 3.7, 4.2]\n",
    "                }\n",
    "\n",
    "canteens_df = pd.DataFrame(canteens_dict)\n",
    "\n",
    "#importing a csv file into a dataframe\n",
    "csv_data = pd.read_csv('data/somedata.csv', header = None)\n",
    "\n",
    "#importing a txt file into a dataframe\n",
    "txt_data = pd.read_table('data/somedata.txt', sep = \"\\s+\", header = None)\n",
    "\n",
    "#importing a xls file into a dataframe\n",
    "xls_data = pd.read_excel('data/somedata.xlsx', sheet_name = 'Sheet1', header = None)\n",
    "\n",
    "#importing a json file into a dataframe\n",
    "json_data = pd.read_json('data/somedata.json')\n",
    "\n",
    "#importing a html website into a dataframe\n",
    "html_data = pd.read_html('http://www.imdb.com/title/tt0441773/fullcredits/?ref_=tt_ov_st_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction from a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting a single coloumn from a data frame by using name of coloumn\n",
    "canteens_df[\"Name\"]\n",
    "\n",
    "#extracting a single row from a data frame\n",
    "canteens_df.iloc[0]\n",
    "\n",
    "#extracting the top n rows from a data frame (default n = 5)\n",
    "canteens_df.head()\n",
    "canteens_df.head(n=n)\n",
    "\n",
    "#extracting a portion of rows from a dataframe\n",
    "canteens_df[a:b] #extracts starting from row a and ends with b-1\n",
    "\n",
    "#extracting a single column from a dataframe and creating a dataframe with that variable (only shows HP column)\n",
    "hp = pd.DataFrame(pkmndata['HP'])\n",
    "\n",
    "#extracting a single type of variable from a dataframe and creating a dataframe with that variable (only shows HP if HP == 1)\n",
    "hp = pd.DataFrame(pkmndata[\"HP\"] == 1)\n",
    "\n",
    "#extracting a single type of variable with all other information included\n",
    "dualtype_gen1 = dualtype_data[dualtype_data[\"Generation\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic functions of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type of dataset\n",
    "type(canteens_df)\n",
    "\n",
    "#finding the shape of a data frame. this returns a tuple where the first number is NoOfRows and second number is NoOfColumns\n",
    "canteens_df.shape\n",
    "\n",
    "#finding the dtypes of each individual column\n",
    "canteens_df.dtypes\n",
    "\n",
    "#info gives more information about the dataset then dtypes\n",
    "canteens_df.info()\n",
    "\n",
    "#describe provides statistical data about the dataset. Describe can only be done on the numerical variables, which is why\n",
    "#describe has less variables than info. some variables look numerical but are actually categorical variables encoded as numbers\n",
    "canteens_df.describe()\n",
    "\n",
    "#changing the type of data\n",
    "houseCatData['MSSubClass'] = houseCatData['MSSubClass'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step guide for importing from a html website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we import from a html website, we may get many dataframes. it is important to check which dataframe we are actually using\n",
    "#eg\n",
    "medal_html = pd.read_html('https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table') #import the html website first\n",
    "medal_html[0] #change index from 0, 1, 2 etc\n",
    "medalTable = medal_html[1] #we realise we are supposed to use the second dataframe, so we extract it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for manipulating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting column names of a dataframe\n",
    "medalTable.columns = medalTable.iloc[0] #this sets the column names to the first row\n",
    "\n",
    "#deleting a row in the dataframe (use index)\n",
    "medalTable = medalTable.drop(0)\n",
    "\n",
    "#obtaining unique variables in a column (returns a list)\n",
    "medalTable[\"variable\"].unique()\n",
    "#obtaining number of each unique variables in a column\n",
    "print(medalTable[\"variable\"].value_counts())\n",
    "#eg a column has the values [1, 2, 3, 3]. the first one returns [1, 2, 3] and the second one returns 1 1, 2 1, 3 3\n",
    "\n",
    "#showing which rows have a null value\n",
    "name = data[pkmn[\"Variable\"].isnull]\n",
    "#showing which rows have a non-null value\n",
    "name = data[pkmn[\"Variable\"].isnull == False]\n",
    "\n",
    "#removing null values\n",
    "data[\"variable\"].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uni-Variate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the dataframe using a boxplot (summary statistics)\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 4))\n",
    "sb.boxplot(hp, orient = \"h\")\n",
    "\n",
    "#showing the dataframe using a histogram with automatic bin sizes (complete distribution)\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, kde = False, color = \"red\")\n",
    "\n",
    "#showing the dataframe using a KDE. a Kernel Density Estimate estimates the pdf of a variable\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, hist = False, color = \"red\")\n",
    "\n",
    "#showing the dataframe with both histogram and a KDE\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, color = \"red\")\n",
    "\n",
    "#showing the dataframe with a violin plot (boxplot combined with the KDE)\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.violinplot(hp)\n",
    "\n",
    "#showing multiple plots together\n",
    "f, axes = plt.subplots(2, 3, figsize=(24, 12)) #first number(ie 2) is the number of rows u want, second number(ie 3) is columns\n",
    "\n",
    "sb.boxplot(hp, orient = \"h\", ax = axes[0,0])\n",
    "sb.distplot(hp, kde = False, ax = axes[0,1])\n",
    "sb.violinplot(hp, ax = axes[0,2]) #plotting all plots together\n",
    "\n",
    "#showing a catplot of countplot\n",
    "sb.catplot(y = \"Type 2\", data = pkmndata, kind = \"count\", height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-Variate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jointplot\n",
    "sb.jointplot(x = attack, y = hp, height = 8)\n",
    "\n",
    "# Create a joint dataframe by concatenating the two variables\n",
    "jointDF = pd.concat([attack, hp], axis = 1, join_axes = [attack.index])\n",
    "\n",
    "# Calculate the correlation between the two columns/variables\n",
    "jointDF.corr()\n",
    "\n",
    "#visualising correlation matrix using heatmap\n",
    "sb.heatmap(jointDF.corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
    "\n",
    "#showing count using heatmap\n",
    "f, axes = plt.subplots(1, 1, figsize=(20, 20))\n",
    "sb.heatmap(dualtype_data.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"BuGn\") #in this example, dualtype_data has to be first\n",
    "#extracted out from main dataframe\n",
    "\n",
    "#showing a catplot of countplot\n",
    "sb.catplot(y = 'Type 1', data = pkmndata, col = 'Generation', kind = 'count', col_wrap = 2, height = 8)\n",
    "\n",
    "#showing a boxplot with 2 variables\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "sb.boxplot(x = 'Neighborhood', y = 'SalePrice', data = houseCatSale)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Variate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the numeric data variables\n",
    "numDF = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])\n",
    "\n",
    "# Summary Statistics for all Variables\n",
    "numDF.describe()\n",
    "\n",
    "# Draw the Boxplots of all variables\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.boxplot(data = numDF, orient = \"h\")\n",
    "\n",
    "# Draw the distributions of all variables\n",
    "f, axes = plt.subplots(6, 2, figsize=(12, 24))\n",
    "\n",
    "count = 0\n",
    "for var in numDF:\n",
    "    sb.distplot(numDF[var], ax = axes[count,0])\n",
    "    sb.violinplot(numDF[var], ax = axes[count,1])\n",
    "    count += 1\n",
    "\n",
    "# Calculate the complete  correlation matrix\n",
    "numDF.corr()\n",
    "\n",
    "# Heatmap of the Correlation Matrix\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "sb.heatmap(numDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")\n",
    "\n",
    "# Draw pairs of variables against one another\n",
    "sb.pairplot(data = numDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a train set of 600 samples and a test set with 200 samples\n",
    "\n",
    "# Train Set : 600 samples\n",
    "hp_train = pd.DataFrame(hp[:600])\n",
    "total_train = pd.DataFrame(total[:600])\n",
    "\n",
    "# Test Set : 200 samples\n",
    "hp_test = pd.DataFrame(hp[-200:])\n",
    "total_test = pd.DataFrame(total[-200:])\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", hp_train.shape, total_train.shape)\n",
    "print(\"Test Set  :\", hp_test.shape, total_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step guide to linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression model from Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linreg.fit(hp_train, total_train) #hp_train was used as predictor and total_train was used as response\n",
    "\n",
    "#You have trained the model to fit the following formula: Regression Problem : Total =  aa   ××  HP +  bb \n",
    "#Check Intercept ( aa ) and Coefficient ( bb ) of the regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "#Plot the regression line based on the coefficients-intercept form\n",
    "# Formula for the Regression line\n",
    "regline_x = hp_train\n",
    "regline_y = linreg.intercept_ + linreg.coef_ * hp_train\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_train, total_train)\n",
    "plt.plot(regline_x, regline_y, 'r-', linewidth = 3)\n",
    "plt.show()\n",
    "\n",
    "#Plot the regression line by prediction using the model\n",
    "# Predict Total values corresponding to HP Train\n",
    "total_train_pred = linreg.predict(hp_train)\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_train, total_train)\n",
    "plt.scatter(hp_train, total_train_pred, color = \"r\")\n",
    "plt.show()\n",
    "\n",
    "#Check how good the predictions are on the Train Set. Metrics : Explained Variance and Mean Squared Error.\n",
    "# Explained Variance (R^2)\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(hp_train, total_train))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "\n",
    "mse = mean_sq_err(total_train, total_train_pred)\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))\n",
    "\n",
    "#Test the Linear Regression model linreg using the Test Set.\n",
    "# Predict Total values corresponding to HP Test\n",
    "total_test_pred = linreg.predict(hp_test)\n",
    "\n",
    "# Plot the Predictions\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_test, total_test, color = \"green\")\n",
    "plt.scatter(hp_test, total_test_pred, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "#Check how good the predictions are on the Train Set. Metrics : Explained Variance and Mean Squared Error.\n",
    "# Explained Variance (R^2)\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(hp_test, total_test))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "mse = mean_sq_err(total_test, total_test_pred)\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by Step for decision tree making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the variables into a new dataframe\n",
    "legnd = pd.DataFrame(pkmndata['Legendary'])  # Response\n",
    "total = pd.DataFrame(pkmndata['Total'])      # Predictor\n",
    "\n",
    "#Set up the classification problem with Train and Test datasets\n",
    "# Train Set : 600 samples\n",
    "total_train = pd.DataFrame(total[:600])\n",
    "legnd_train = pd.DataFrame(legnd[:600])\n",
    "\n",
    "# Test Set : 200 samples\n",
    "total_test = pd.DataFrame(total[-200:])\n",
    "legnd_test = pd.DataFrame(legnd[-200:])\n",
    "\n",
    "# Import Decision Tree Classifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier object\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)\n",
    "\n",
    "# Train the Decision Tree Classifier model\n",
    "dectree.fit(total_train, legnd_train)\n",
    "\n",
    "# Import export_graphviz from sklearn.tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Export the Decision Tree as a dot object\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = total_train.columns,          # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "# Render using graphviz\n",
    "import graphviz\n",
    "graphviz.Source(treedot)\n",
    "\n",
    "#Check how good the predictions are on the Train Set. Metrics : Classification Accuracy and Confusion Matrix.\n",
    "# Predict Legendary corresponding to Total Train\n",
    "legnd_train_pred = dectree.predict(total_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(total_train, legnd_train))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(legnd_train, legnd_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})\n",
    "\n",
    "#Check how good the predictions are on the Test Set. Metrics : Classification Accuracy and Confusion Matrix.\n",
    "# Predict Legendary corresponding to Total Test\n",
    "legnd_test_pred = dectree.predict(total_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(total_test, legnd_test))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(legnd_test, legnd_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})\n",
    "\n",
    "#Split the Train and Test sets randomly, and perform Classification.\n",
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Recall the Legendary-Total Dataset\n",
    "legnd = pd.DataFrame(pkmndata['Legendary'])   # Response\n",
    "total = pd.DataFrame(pkmndata['Total'])       # Predictor\n",
    "\n",
    "# Split the Legendary-Total Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(total, legnd, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Legendary values corresponding to Total\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
